import streamlit as st
import pandas as pd

# --- å°ˆæ¥­ç®¡ç†ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="GLA Boar System v6.6", layout="wide")

st.markdown("""
    <style>
    .block-container { padding-top: 1.5rem; }
    h2 { 
        font-size: 18px !important; color: #1E3A8A; font-weight: bold; 
        border-left: 5px solid #1E3A8A; padding: 10px 0 10px 15px; 
        margin-top: 30px !important; margin-bottom: 15px;
    }
    .stTable td, .stTable th { text-align: center !important; vertical-align: middle !important; }
    </style>
    """, unsafe_allow_html=True)

@st.cache_data(ttl=300)
def fetch_data(gid):
    sheet_id = "1qvo4INF0LZjA2u49grKW_cHeEPJO48_dk6gOlXoMgaM"
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&gid={gid}"
    try:
        # ä½¿ç”¨ header=None ä»¥ç‰©ç†ç´¢å¼•æ“ä½œï¼Œé¿å…æ¨™é¡Œç²˜é€£å ±éŒ¯
        df = pd.read_csv(url, header=None)
        # é—œéµä¿®æ­£ï¼šç§»é™¤æ‰€æœ‰æ•¸æ“šä¸­å¯èƒ½çš„éš±è—ç©ºæ ¼
        df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
        return df
    except Exception as e:
        st.error(f"é€£ç·šå¤±æ•—: {e}")
        return None

# è®€å–æ•¸æ“š (åˆ†é  GID: 1428367761)
df_raw = fetch_data("1428367761")

# --- 1. æŸ¥è©¢æ¡†æ¶ ---
st.markdown("## ğŸ” æœå°‹å…¬è±¬è€³è™Ÿ / SEARCH BOAR ID")
search_id = st.text_input("", placeholder="è¼¸å…¥è€³è™Ÿ (ä¾‹å¦‚: D1397)...", label_visibility="collapsed").strip()

if df_raw is not None and search_id:
    try:
        # è·³éå‰å…©è¡Œæ¨™é¡Œï¼Œæ•¸æ“šå¾ç´¢å¼• 2 é–‹å§‹
        data_rows = df_raw.iloc[2:].copy()
        
        # æœå°‹ç´¢å¼• 23 (X æ¬„ï¼ŒTag ID)
        # å¼·åˆ¶è½‰æ›ç‚ºå­—ä¸²æ¯”å°ï¼Œä¸¦æ’é™¤ç©ºå€¼å½±éŸ¿
        res = data_rows[data_rows[23].astype(str).str.fullmatch(search_id, case=False, na=False)]
        
        if not res.empty:
            match_row = res.iloc[[0]] # é–å®šç¬¬ä¸€ç­†åŒ¹é…

            # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šè¡¨ä¸€ (V:AD åº§æ¨™ 21-29) ---
            st.markdown("## I. å…¬è±¬ç­‰ç´šèˆ‡è³‡è¨Š (BOAR INFORMATION)")
            df_v_ad = match_row.iloc[:, 21:30].copy() 
            df_v_ad.columns = [
                'Grade', 'Breed', 'Tag ID', 'Index Score', 
                'Strategy (ç­–ç•¥)', 'Avg TSO', 'Mated', 'CR %', 'Avg Birth Wt'
            ]
            
            # æ•¸æ“šæ¸…ç†èˆ‡ç„¡å°æ•¸é»é¡¯ç¤º (è§£æ±º 17.0000 å•é¡Œ)
            for col in df_v_ad.columns:
                df_v_ad[col] = pd.to_numeric(df_v_ad[col], errors='ignore')
                if df_v_ad[col].dtype in ['float64', 'int64']:
                    df_v_ad[col] = df_v_ad[col].fillna(0).astype(int)
            st.table(df_v_ad)

            # --- ç¬¬äºŒéƒ¨åˆ†ï¼šè¡¨äºŒæ•´ä½µå„ªåŒ– (åº§æ¨™èµ·é» 79) ---
            st.markdown("## II. æœ€è¿‘å…­é€±æ¡ç²¾åˆ†æ (INTEGRATED REPORT)")
            
            # é¡¯ç¤ºåŸºç¤è³‡è¨Š
            st.info(f"ğŸ§¬ **Breed:** {match_row.iloc[0, 22]} | ğŸ·ï¸ **Tag ID:** {match_row.iloc[0, 23]}")

            # æ ¹æ“šåŸå§‹è³‡æ–™æ ¡æ­£ï¼šW06 æ•¸æ“šèµ·é»åœ¨ CB æ¬„ (ç´¢å¼• 79)
            anchor_idx = 79 
            
            metrics_setup = [
                ("ğŸ“ˆ 3. Usage Frequency (Times)", anchor_idx),
                ("âš¡ 4. Sperm Vitality (Avg)", anchor_idx + 6),
                ("ğŸ’§ 5. Sperm Concentration (Avg)", anchor_idx + 12),
                ("âš ï¸ 6. Impurities (%)", anchor_idx + 18),
                ("ğŸ¥› 7. History Volume (ml)", anchor_idx + 24)
            ]
            
            weeks_label = ['W06', 'W05', 'W04', 'W03', 'W02', 'W01']
            combined_data = []

            for label, s_idx in metrics_setup:
                # æŠ“å–è©²æŒ‡æ¨™æ­£ç¢ºçš„ 6 æ¬„æ•¸å€¼
                row_vals = match_row.iloc[0, s_idx:s_idx + 6].tolist()
                combined_data.append([label] + row_vals)
            
            df_final = pd.DataFrame(combined_data, columns=['Performance Metric / é€±æ¬¡æŒ‡æ¨™'] + weeks_label)
            
            # æ•¸å€¼æ•´æ•¸åŒ–
            for col in weeks_label:
                df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0)
                df_final[col] = df_final[col].astype(int)

            st.table(df_final)
                        
        else:
            st.error(f"æŸ¥ç„¡è€³è™Ÿ: '{search_id}'ï¼Œè«‹ç¢ºèªè€³è™Ÿæ˜¯å¦æ­£ç¢ºè¼¸å…¥ã€‚")
    except Exception as e:
        st.error(f"è§£æéŒ¯èª¤: {e}")
else:
    st.info("ğŸ’¡ è«‹è¼¸å…¥å…¬è±¬è€³è™Ÿã€‚")
