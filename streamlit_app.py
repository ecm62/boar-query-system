import streamlit as st
import pandas as pd

# --- å°ˆæ¥­ç®¡ç†ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="GLA Boar System v6.0", layout="wide")

st.markdown("""
    <style>
    .block-container { padding-top: 1.5rem; }
    h2 { 
        font-size: 18px !important; color: #1E3A8A; font-weight: bold; 
        border-left: 5px solid #1E3A8A; padding: 10px 0 10px 15px; 
        margin-top: 30px !important; margin-bottom: 15px;
    }
    .stTable td, .stTable th { text-align: center !important; vertical-align: middle !important; }
    </style>
    """, unsafe_allow_html=True)

@st.cache_data(ttl=300)
def fetch_data(gid):
    sheet_id = "1qvo4INF0LZjA2u49grKW_cHeEPJO48_dk6gOlXoMgaM"
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&gid={gid}"
    try:
        # ä½¿ç”¨ header=None ä»¥ç‰©ç†æ–¹å¼è®€å–æ•´å¼µè¡¨ï¼Œé¿å…é‡è¤‡æ¨™é¡Œå ±éŒ¯
        df = pd.read_csv(url, header=None)
        return df
    except Exception as e:
        st.error(f"é€£ç·šå¤±æ•—: {e}")
        return None

df_raw = fetch_data("1428367761")

if df_raw is not None:
    # å–å¾—æ¨™é¡Œåˆ— (Row 2) ç”¨æ–¼å‹•æ…‹å®šä½
    header_row = df_raw.iloc[1].fillna('').astype(str).tolist()
    header_row = [c.strip().replace('\n', ' ') for c in header_row]

    # --- 1. æŸ¥è©¢æ¡†æ¶ ---
    st.markdown("## ğŸ” æœå°‹å…¬è±¬è€³è™Ÿ / SEARCH BOAR ID")
    search_id = st.text_input("", placeholder="è¼¸å…¥è€³è™Ÿ (ä¾‹å¦‚: D1397)...", label_visibility="collapsed").strip()

    if search_id:
        try:
            # å®šä½ Tag ID æ¬„ä½ (é€šå¸¸åœ¨ X æ¬„)
            tag_idx = next(i for i, c in enumerate(header_row) if 'tag id' in c.lower())
            
            data_rows = df_raw.iloc[2:] 
            res = data_rows[data_rows[tag_idx].astype(str).str.fullmatch(search_id, case=False, na=False)]
            
            if not res.empty:
                # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šè‚²ç¨®è³‡è¨Š (å›ºå®š V:AD åº§æ¨™) ---
                st.markdown("## I. å…¬è±¬ç­‰ç´šèˆ‡è³‡è¨Š (BOAR INFORMATION)")
                df_v_ad = res.iloc[:, 21:30].copy() 
                df_v_ad.columns = ['Grade', 'Breed', 'Tag ID', 'Index Score', 'Strategy (ç­–ç•¥)', 'Avg TSO', 'Mated', 'CR %', 'Avg Birth Wt']
                
                # æ•¸å€¼æ•´æ•¸åŒ– (è§£æ±ºæˆªåœ–ä¸­ 17.0000 çš„å•é¡Œ)
                for col in df_v_ad.columns:
                    df_v_ad[col] = pd.to_numeric(df_v_ad[col], errors='ignore')
                    if df_v_ad[col].dtype in ['float64', 'int64']:
                        df_v_ad[col] = df_v_ad[col].fillna(0).astype(int)
                st.table(df_v_ad)

                # --- ç¬¬äºŒéƒ¨åˆ†ï¼šå‹•æ…‹æ ¡æ­£æ¡ç²¾åˆ†æ (BY:CG) ---
                st.markdown("## II. æœ€è¿‘å…­é€±æ¡ç²¾æ•´åˆåˆ†æ (INTEGRATED REPORT)")
                
                # å‹•æ…‹å°‹æ‰¾ BY æ¬„ä½çš„éŒ¨é» (W06 + Usage)
                try:
                    # åœ¨æ¨™é¡Œåˆ—æœå°‹åŒ…å« W06 ä¸”åŒ…å« Usage çš„ç´¢å¼•
                    anchor_idx = next(i for i, c in enumerate(header_row) if 'w06' in c.lower() and 'usage' in c.lower())
                except StopIteration:
                    # å¦‚æœæœå°‹å¤±æ•—ï¼Œå‰‡æ ¹æ“šæˆªåœ–åç§»é‡æ¨ç®—ï¼ŒDuroc å‡ºç¾åœ¨ Usage ä»£è¡¨æˆ‘å€‘åŸæœ¬ç´¢å¼• 76 å¤ªå‰é¢äº†
                    # æˆªåœ–é¡¯ç¤ºåç§»äº†ç´„ 54 æ¬„ï¼Œé€™è£¡æ”¹ç”¨å®‰å…¨æœå°‹
                    anchor_idx = 76 # å‚™æ´å€¼

                # å®šç¾©æŒ‡æ¨™æ¨™ç±¤èˆ‡é–“è·
                metrics_setup = [
                    ("ğŸ“ˆ 3. Usage Frequency (Times)", anchor_idx),
                    ("âš¡ 4. Sperm Vitality (Avg)", anchor_idx + 6),
                    ("ğŸ’§ 5. Sperm Concentration (Avg)", anchor_idx + 12),
                    ("âš ï¸ 6. Impurities (%)", anchor_idx + 18),
                    ("ğŸ¥› 7. History Volume (ml)", anchor_idx + 24)
                ]
                
                weeks_label = ['W06', 'W05', 'W04', 'W03', 'W02', 'W01']
                combined_data = []

                for label, start_s in metrics_setup:
                    # æŠ“å–è©²æŒ‡æ¨™çš„ 6 é€±æ•¸æ“š
                    vals = res.iloc[0, start_s:start_s + 6].tolist()
                    combined_data.append([label] + vals)
                
                # å»ºç«‹æ•´åˆè¡¨æ ¼
                df_integrated = pd.DataFrame(combined_data, columns=['Performance Metric / é€±æ¬¡æŒ‡æ¨™'] + weeks_label)
                
                # æ•¸æ“šæ¸…æ´—ï¼šå¼·åˆ¶è½‰æ›ç‚ºæ•´æ•¸ï¼Œè‹¥ç‚ºæ–‡å­—(å¦‚æˆªåœ–ä¸­çš„å“ç¨®å)å‰‡ä¿æŒä»¥ä¾¿é™¤éŒ¯
                for col in weeks_label:
                    df_integrated[col] = pd.to_numeric(df_integrated[col], errors='coerce').fillna(df_integrated[col])
                    df_integrated[col] = df_integrated[col].apply(lambda x: int(x) if isinstance(x, (int, float)) and not pd.isna(x) else x)

                # é¡¯ç¤ºåŸºç¤è³‡è¨Šåˆ—
                breed_idx = next(i for i, c in enumerate(header_row) if 'breed' in c.lower())
                st.info(f"ğŸ§¬ **Breed:** {res.iloc[0, breed_idx]} | ğŸ·ï¸ **Tag ID:** {res.iloc[0, tag_idx]}")
                
                st.table(df_integrated)
                        
            else:
                st.error(f"æŸ¥ç„¡è€³è™Ÿ: {search_id}")
        except Exception as e:
            st.error(f"ç³»çµ±è§£æç•°å¸¸: {e}ã€‚è«‹ç¢ºèªè©¦ç®—è¡¨ Row 2 æ¨™é¡ŒåŒ…å« 'W06' èˆ‡ 'Usage'ã€‚")
else:
    st.info("ğŸ’¡ è«‹è¼¸å…¥å…¬è±¬è€³è™Ÿé€²è¡Œæ•¸æ“šæª¢ç´¢ã€‚")
